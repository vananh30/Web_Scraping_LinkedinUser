{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "780608e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9d99f3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmail = ['']\n",
    "password = ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ac4c573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(browser):\n",
    "    browser.get('https://www.linkedin.com/login?fromSignIn=true&trk=guest_homepage-basic_nav-header-signin')\n",
    "    time.sleep(5)\n",
    "    browser.find_element(\"name\", \"session_key\").send_keys('' + Keys.RETURN)\n",
    "    browser.find_element(\"name\", \"session_password\").send_keys('' + Keys.RETURN)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90a656b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe into MySQL\n",
    "import sqlalchemy\n",
    "def etl_mysql():\n",
    "    database_username = 'root'\n",
    "    database_password = ''\n",
    "    database_ip       = 'localhost'\n",
    "    database_name     = 'LINKEDIN_USER'\n",
    "    database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                                   format(database_username, database_password, \n",
    "                                                          database_ip, database_name))\n",
    "    return database_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b42aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = etl_mysql()\n",
    "import pandas as pd\n",
    "query = \"select * from users\"\n",
    "users = pd.read_sql(query, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "29539124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_scrape_profile(browser, proFileLink):\n",
    "    browser.get(proFileLink)\n",
    "    time.sleep(5)\n",
    "    soup = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    time.sleep(2)\n",
    "    proFileLink = proFileLink.split('?')[0] + '/'\n",
    "    browser.get(proFileLink + 'details/experience/')\n",
    "    time.sleep(5)\n",
    "    soup_exp = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    time.sleep(2)\n",
    "    browser.get(proFileLink + 'details/skills/')\n",
    "    time.sleep(5)\n",
    "    soup_skill = BeautifulSoup(browser.page_source, 'html.parser')\n",
    "    time.sleep(30)\n",
    "    return soup, soup_exp, soup_skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f20d6c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def experiences(soup_exp):\n",
    "    info_ex = soup_exp.find_all('li', class_ = 'pvs-list__paged-list-item artdeco-list__item pvs-list__item--line-separated')\n",
    "    experiences = {}\n",
    "    if(len(info_ex) > 0):\n",
    "        for i in range(len(info_ex)):\n",
    "            job_title = info_ex[i].find_all('span', class_ = 'mr1 t-bold')\n",
    "            job_title = list(map(lambda x: replace_(x.find_all('span')[0].text), job_title))\n",
    "            company = info_ex[i].find_all('span', class_ ='t-14 t-normal')\n",
    "            duration = info_ex[i].find_all('span', class_ ='t-14 t-normal t-black--light')\n",
    "            if(len(job_title) == len(company) and (len(duration) -1 ) == len(job_title)):\n",
    "                company = list(map(lambda x: replace_(x.find_all('span')[0].text), company))\n",
    "                duration_ = replace_(duration[0].find_all('span')[0].text.strip())\n",
    "                location = replace_(duration[1].find_all('span')[0].text.strip())\n",
    "                res = {'Job Title':job_title, 'Company': company, 'Duration': duration_,'Location': location  }\n",
    "            elif(len(job_title) != len(company) and (len(duration) -1 ) == len(job_title)):\n",
    "                duration_ = replace_(duration[0].find_all('span')[0].text.strip())\n",
    "                location = replace_(duration[1].find_all('span')[0].text.strip())\n",
    "                res = {'Job Title':job_title, 'Company': \"Null\", 'Duration': duration_,'Location': location  }\n",
    "            else:\n",
    "                company = list(map(lambda x: replace_(x.find_all('span')[0].text), company))\n",
    "                res = {\"Job Title\":job_title, \"Company\": company, 'Duration': \"Null\",\"Location\": \"Null\"  }\n",
    "            experiences[i] = res\n",
    "    return json.dumps(experiences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f532a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skills(soup_skill):\n",
    "    info_skill = soup_skill.find_all('span', class_ = 'mr1 t-bold')\n",
    "    skills_ = {}\n",
    "    if(len(info_skill) > 0): \n",
    "        for i in range(len(info_skill)):\n",
    "            skills_[i] = replace_(info_skill[i].find_all('span')[0].text)\n",
    "    return json.dumps(skills_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f140cfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def honors(honor_info):\n",
    "    honors_ = {}\n",
    "    honors = honor_info.find_all('span', attrs={'class': 'mr1 t-bold'})\n",
    "    honors_issues = honor_info.find_all('span', attrs={'class': 't-14 t-normal'})\n",
    "    honors = list(map(lambda x: replace_(x.find_all('span')[0].text), honors) )\n",
    "    honors_issues = list(map(lambda x: replace_(x.find_all('span',attrs={'class': 'visually-hidden'})[0].text), honors_issues))\n",
    "    if(len(honors) == len(honors_issues) and len(honors) != 0):\n",
    "        for j in range(len(honors)):\n",
    "            res = {\"HonorName\": honors[j], \"Issue\": honors_issues[j] }\n",
    "            honors_[j] = res\n",
    "    return json.dumps(honors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83210116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def educations(education_info):\n",
    "    educations_ = {}\n",
    "    educations = education_info.find_all('span', attrs={'class': 'mr1 hoverable-link-text t-bold'})\n",
    "    educations = list(map(lambda x: x.find_all('span')[0].text, educations))\n",
    "    majors = education_info.find_all('span', attrs={'class': 't-14 t-normal'})\n",
    "    majors = list(map(lambda x: x.find_all('span',attrs={'class': 'visually-hidden'})[0].text, majors))\n",
    "    durations = education_info.find_all('span', attrs={'class': 't-14 t-normal t-black--light'})\n",
    "    durations = list(map(lambda x: x.find_all('span',attrs={'class': 'visually-hidden'})[0].text, durations))\n",
    "    for j in range(len(educations)):\n",
    "        if(len(educations) == len(majors) == len(durations)):\n",
    "            res = {\"School\": replace_(educations[j]), \"Major\": replace_(majors[j]), \"Duration\":replace_(durations[j])  }\n",
    "        elif (len(educations) == len(majors) and len(educations)!= len(durations)):\n",
    "            print(educations[j])\n",
    "            res = {\"School\": replace_(educations[j]), \"Major\": replace_(majors[j]), \"Duration\": \"Null\"}\n",
    "        elif (len(educations) == len(durations) and len(educations)!= len(majors)):\n",
    "            res = {\"School\": replace_(educations[j]), \"Major\": \"Null\", \"Duration\":replace_(durations[j])  }\n",
    "        else:\n",
    "             res = {\"School\": replace_(educations[j]), \"Major\": \"Null\", \"Duration\": \"Null\" }\n",
    "        educations_[j] = res\n",
    "        \n",
    "    return json.dumps(educations_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "442b2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_(str_):\n",
    "    return str_.replace(\"'\", \"\").replace(\"\\t\", \"\").replace(\"\\uf0a7\\t\", \"\").replace(\"'\", \"\").replace('\"', '').replace(u'\\u00b7', \"\").replace(u'\\u00c7', \"\").replace(u'\\00c3', \"\").replace(u'\\u00d5', \"\").replace('\\n', \"\").replace(u'\\u00fc', \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5be59f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publications(publication_info):\n",
    "    pubications_ = {}\n",
    "    publications = publication_info.find_all('span', attrs={'class': 'mr1 t-bold'})\n",
    "    publications = list(map(lambda x: replace_(x.find_all('span')[0].text), publications))\n",
    "    pub_urls = publication_info.find_all('a')\n",
    "    pub_urls = list(map(lambda x: x.get('href'), pub_urls)) \n",
    "    for i in range(len(publications)):\n",
    "        if(len(publications) == len(pub_urls)):\n",
    "            res = {'Name' : publications[i], \"URL\" : pub_urls[i] }\n",
    "        else:\n",
    "            res = {'Name' : publications[i], \"URL\" : 'Null' }\n",
    "        pubications_[i] = res\n",
    "    return json.dumps(pubications_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e39d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_profile_sections(soup,soup_exp,soup_skill):\n",
    "    name_ = soup.find_all('h1', class_ = 'text-heading-xlarge inline t-24 v-align-middle break-words')\n",
    "    cur_pos_ = soup.find_all('div', attrs={'class': 'text-body-medium break-words'})\n",
    "    position_ = soup.find_all('span', attrs={'class': 'text-body-small inline t-black--light break-words'})\n",
    "    about_ = soup.find_all('div', attrs={'class': 'display-flex ph5 pv3'})\n",
    "    img_ = soup.find_all('img', class_ = 'pv-top-card-profile-picture__image pv-top-card-profile-picture__image--show ember-view')\n",
    "    if(len(name_) != 0): name_ = replace_(name_[0].text)\n",
    "    if(len(cur_pos_) != 0): cur_pos_ = replace_(cur_pos_[0].text.strip())\n",
    "    if(len(position_) != 0):  position_ = replace_(position_[0].text.strip())\n",
    "    if(len(about_) != 0) : about_ = replace_(about_[0].text.strip())\n",
    "    if(len(img_) != 0) : img_ = img_[0].get('src')\n",
    "    \n",
    "    #extract all section\n",
    "    info = soup.find_all('section', attrs={'class': 'artdeco-card ember-view relative break-words pb3 mt2'})\n",
    "    education = []\n",
    "    honor = []\n",
    "    langueage = []\n",
    "    name = []\n",
    "    cur_pos = []\n",
    "    position = []\n",
    "    about = []\n",
    "    img = []\n",
    "    publication = []\n",
    "    experience = [experiences(soup_exp)]\n",
    "    skill = [skills(soup_skill)]\n",
    "    profile = [name, cur_pos, position, about, education,honor,publication, langueage, img, experience,skill ]\n",
    "    name.append(name_)\n",
    "    cur_pos.append(cur_pos_)\n",
    "    position.append(position_)\n",
    "    about.append(about_)\n",
    "    img.append(img_)\n",
    "    \n",
    "    for i in range(len(info)):\n",
    "        section = info[i].find_all('div', attrs={'class': 'pvs-header__title-container'})[0].find_all('span')[0].text\n",
    "        if(section == 'Education'):\n",
    "            education.append(educations(info[i]))\n",
    "        elif(section == 'Honors & awards'):\n",
    "            honor.append(honors(info[i]))\n",
    "        elif (section == 'Languages'):\n",
    "            langueages = info[i].find_all('span', attrs={'class': 'mr1 t-bold'})\n",
    "            langueages = list(map(lambda x: x.find_all('span')[0].text, langueages))\n",
    "            langueages = json.dumps(langueages)\n",
    "            langueage.append(langueages)\n",
    "        elif (section == 'Publications'):\n",
    "            publication.append(publications(info[i]))\n",
    "    for section in profile:\n",
    "        if len(section) == 0:\n",
    "            section.append([])\n",
    "    df = pd.DataFrame({'Name': name,'Job Title':cur_pos,'Location':position,'Image': img,'About': about  , 'Education':education, 'Experience': experience, 'Skill': skill,'Honors & awards':honor,'Publication': publication,'Languages':langueage })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "122b250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df):\n",
    "    df_insert = (\"\"\"\n",
    "    INSERT INTO profile(Name, `Job Title`,`Location` ,`Image` ,`About` ,`Education` ,`Experience` ,`Skill`,`Honors & awards`,`Publication`, `Languages`)\n",
    "    VALUES ( \n",
    "    \"\"\")\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].astype('string')\n",
    "        df_insert +=  \"'\"+ df.iloc[0][col] +\"'\"  + ','\n",
    "    t = df_insert[:-2] +\"')\"\n",
    "    conn.execute(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a2ad1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "browser = webdriver.Chrome(ChromeDriverManager().install())\n",
    "login(browser)\n",
    "count = 0\n",
    "for i in  range(len(users.Profile)):\n",
    "        print('Scraping profile of user: ', users.Name[0] ,' index ', i )\n",
    "        soup, soup_exp, soup_skill = user_scrape_profile(browser, users.Profile[i]) \n",
    "        df = extract_profile_sections(soup, soup_exp, soup_skill)\n",
    "        load_data(df)\n",
    "        print('Sucessfully uploading profile of user: ', users.Name[0] ,' index ', i )\n",
    "        count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b9872e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
